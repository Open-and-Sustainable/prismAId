[project]
name = "Test of prismAId"
author = "Riccardo Boero"
version = "0.1"

[project.configuration]
input_directory = "../projects/input/test" # where the .txt files are
results_file_name = "../projects/output/test/output" # where results will be saved, the path must exists, file extension will be added
output_format = "csv"  # Could be "csv" [default] or "json"
log_level = "low" # Could be "low" [default], "medium" showing entries on stdout, or "high" saving entries on file, see user manual for details

[project.llm]
provider = "OpenAI" # Only OpenAI is supported so far
api_key = "" # If left empty, it will search for an API key in env variables. Adding a key here is useful for tracking costs per prokect through project keys
model = "" # Could be 'gpt-4-turbo', 'gpt-3.5-turbo', or '' [default]. Leave empty string (or remove key) if you want cost optimizatoin: it will switch between ChatGPT4 Turbo and ChatGPT3.5 Turbo according to the cost of the model ad the limits on input tokens
temperature = 0.2 # Between 0 and 1. Low model temperature to decrease randomness and ensure replicability
batch_execution = "no" # Coul be "yes" [default] or "no". If yes it will send the prompt as batch jobs executed in 24 hours and costing 50%. Not yet implemented!


[prompt]
persona = "You are an experienced scientist reviewing scientific literature to map the methods used by other scientists in the field." 
task = "You are asked to map the concepts discussed in a scientific paper attached here."
expected_result = "You should output a JSON object with the following keys and possible values: "
failsafe = "For the key 'historical period studied', provide any relevant period or era mentioned in the document. If the concepts neither are clearly discussed in the document nor they can be deduced from the text, respond with an empty '' value."
definitions = "'Historical data analysis' refers to the examination and interpretation of past observed or modeled data to identify patterns, trends, and insights. 'Forecasting' refers to using models to predict future scenarios or variables of interest. 'Copulas' refer to statistical methods used to join multiple statistical distributions to model their dependencies. 'Regression models' refer to statistical models that utilize linear and nonlinear regression techniques to analyze relationships between variables. 'Clustering' refers to statistical methods for defining groups or patterns of similar data points based on similarities, distances, or multinomial characteristics. 'Bayesian approach' refers to a statistical method that incorporates prior knowledge or beliefs, updating them with new data to form posterior probabilities. 'Geographical scale' refers to the spatial level at which analysis is conducted. 'Historical period studied' refers to the time period of interest in historical data analysis."
example = ""

[review] # Review items -- defining the knowledge map that needs to be filled in
[review.1]
key = "historical data analysis"
values = ["yes", "no"]
[review.2]
key = "forecasting"
values = ["yes", "no"]
[review.3]
key = "copulas"
values = ["yes", "no"]
[review.4]
key = "regression models"
values = ["yes", "no"]
[review.5]
key = "clustering"
values = ["yes", "no"]
[review.6]
key = "bayesian approach"
values = ["yes", "no"]
[review.7]
key = "geographical scale"
values = ["world", "continent", "river basin"]
[review.8]
key = "historical period studied"
values = []